# I trained my dataset on Google Colab
# model path is from drive 
# When training after every epoch it saves the best model in best_fracture.pth file 
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torchvision import models, transforms
from PIL import Image, ImageFile
import pandas as pd
import numpy as np
import os
import matplotlib.pyplot as plt
from sklearn.metrics import classification_report, confusion_matrix, recall_score
import seaborn as sns
from tqdm import tqdm

ImageFile.LOAD_TRUNCATED_IMAGES = True
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

MODEL_PATH = "/content/drive/MyDrive/Fracture_Detection/best_fracture.pth"

class CSVDataset(Dataset):
    def __init__(self, csv_file, img_dir, transform=None):
        self.df = pd.read_csv(csv_file)
        self.img_dir = img_dir
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        row = self.df.iloc[idx]
        label = int(row['fractured'])
        folder = "Fractured" if label == 1 else "Non_fractured"
        img_path = os.path.join(self.img_dir, folder, str(row['image_id']))

        try:
            image = Image.open(img_path).convert('RGB')
        except:
            image = Image.new('RGB', (224, 224), (0, 0, 0))

        if self.transform:
            image = self.transform(image)
        return image, label

def get_transforms():
    train_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    val_transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
    ])
    return train_transform, val_transform

def create_model():
    model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)
    num_ftrs = model.fc.in_features
    model.fc = nn.Sequential(
        nn.Linear(num_ftrs, 512),
        nn.ReLU(),
        nn.Dropout(0.5),
        nn.Linear(512, 2)
    )
    return model.to(device)

def main():
    DATA_DIR = "/content/drive/MyDrive/Dataset/FracAtlas"
    IMG_DIR = os.path.join(DATA_DIR, "images")
    PROCESSED_DIR = os.path.join(DATA_DIR, "processed_data")

    train_transform, val_transform = get_transforms()

    if not os.path.exists(PROCESSED_DIR):
        print(f"ERROR: Data directory not found at {PROCESSED_DIR}")
        return

    train_ds = CSVDataset(os.path.join(PROCESSED_DIR, "train.csv"), IMG_DIR, train_transform)
    val_ds = CSVDataset(os.path.join(PROCESSED_DIR, "val.csv"), IMG_DIR, val_transform)
    test_ds = CSVDataset(os.path.join(PROCESSED_DIR, "test.csv"), IMG_DIR, val_transform)

    train_loader = DataLoader(train_ds, batch_size=32, shuffle=True)
    val_loader = DataLoader(val_ds, batch_size=32, shuffle=False)
    test_loader = DataLoader(test_ds, batch_size=32, shuffle=False)

    model = create_model()

    if os.path.exists(MODEL_PATH):
        print("Loading existing weights...")
        model.load_state_dict(torch.load(MODEL_PATH, map_location=device))

    os.makedirs(os.path.dirname(MODEL_PATH), exist_ok=True)

    criterion = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 5.0]).to(device))
    optimizer = optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-4)

    best_recall = 0.0
    epochs = 15

    print("Starting Training focused on Recall...")
    for epoch in range(epochs):
        model.train()
        for imgs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{epochs}"):
            imgs, labels = imgs.to(device), labels.to(device)
            optimizer.zero_grad()
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

        model.eval()
        all_preds, all_labels = [], []
        with torch.no_grad():
            for imgs, labels in val_loader:
                imgs, labels = imgs.to(device), labels.to(device)
                outputs = model(imgs)
                _, preds = torch.max(outputs, 1)
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.cpu().numpy())

        val_recall = recall_score(all_labels, all_preds, pos_label=1)
        val_acc = (np.array(all_preds) == np.array(all_labels)).mean()

        print(f"Epoch {epoch+1}: Acc {val_acc:.4f} | Recall (Fractures) {val_recall:.4f}")

        if val_recall >= best_recall:
            best_recall = val_recall
            torch.save(model.state_dict(), MODEL_PATH)
            print(f"--> Saved better Sensitivity model (Recall: {val_recall:.4f})")

    print("\n--- Final Test Evaluation ---")
    model.load_state_dict(torch.load(MODEL_PATH))
    model.eval()
    all_preds, all_labels = [], []
    with torch.no_grad():
        for imgs, labels in test_loader:
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            _, preds = torch.max(outputs, 1)
            all_preds.extend(preds.cpu().numpy())
            all_labels.extend(labels.cpu().numpy())

    print(classification_report(all_labels, all_preds, target_names=['Normal', 'Fractured']))

    cm = confusion_matrix(all_labels, all_preds)
    plt.figure(figsize=(6,5))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Reds',
                xticklabels=['Normal', 'Fractured'],
                yticklabels=['Normal', 'Fractured'])
    plt.xlabel('Predicted'); plt.ylabel('Actual'); plt.title('Confusion Matrix (Recall Optimized)')
    plt.show()

if __name__ == "__main__":
    main()